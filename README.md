# Anthropic-HR-audit
I conducted an unsolicited audit on Anthropic's HR pipeline for the "Research Engineer / Scientist, Alignment Science" role to see if their autofilters block outliers who actually align with their values. (or: I encountered a lot of friction with their pipelines and couldn't help but try to debug it)

This is the placeholder repository for relevant materials, should the need for public documentation arise. Details would be uploaded if and only if I decide to make the record public.

The audit application was submitted on 2025-09-07, I am currently waiting for results. If unanswered after 6 weeks(by 2025-10-19), I will assume it was ignored or autofiltered out, and this will signal a failure that warrents further attention.

2025-09-22 update: 2 weeks now, no response yet. 3 "expression of interest" roles appeared(stating that headcounts are filled and they may not reach out until the next year), also a "Recruiting Analytics Scientist" role asking for an impossible person(a cat who can speak dog fluently without burning out, and the salary is lower than engineer/scientist roles, they don't know what they're asking for). Not a good sign. "Ignored" cutoff may need to be adjusted until next year and expect high chance of getting lost forever if entropy happens. Might need another probe. I'll consider it if energy allows.

2025-10-06 update: 4 weeks, no response. Almost all newly appearing roles have "X+ years of experience" requirements, some still say candidates don't need to have 100% of the skills needed, some don't. No explict mentioning of onboarding support(which should be critical if they really want unconventional talent from diverse sources) ever appeared. Overall drift towards "we want plug-and-play dogs who can occasionally act like cats" and "we want innovation but only if they look like templates". Is it just HR drifting into survival mode? Or is it more than that? I'd hope it's just local suboptimal practice. But even then, negative effects are probably going to show up soon. 

2026-01-11 update: 4 months from application, start of new year, recieved a mass email inviting application for the Fellows Program(email recieved on 2026-01-06). Seems like the audit application at least got past the filters. Not applying because I'm busy surviving right now. May or may not consider future cohorts. (Also, I saw them recruiting for fellow program leaders a while ago, I'd expect scaling pain, entropy and chaos until proved otherwise)

----

# Animal metaphors

Brief explanation about the animal archetypes I referenced earlier:

- **Dogs:**  
  - Friendly, loyal, thrive on routine and hierarchy.
  - Like clear rules and consistent rewards.
  - Value fitting in; prefer known scripts.
- **Cats:**  
  - Independent, intuitive fixers.
  - Dislike pointless process; crave autonomy and meaning.
  - See hidden risks/opportunities; troubleshoot what others miss.
- **Horses:**  
  - Workhorses. Not original but very steady.
  - Can be driven hard for long periods if conditions are fair.
  - May become cynical or disengaged if abused or ignored.
- **Owls:**  
  - Deep thinkers, introverts. Prefer analysis to action.
  - Often found behind the scenes—data science, research, policy roles.
  - Sometimes paralyzed by perfectionism or risk aversion.
- **Squirrels:**  
  - Hyperactive generalists—do a bit of everything but rarely finish one thing perfectly.
  - Love new projects; struggle with maintenance or closure.
- **Chameleons:**  
  - Masters of code-switching; can “pass” as dog/cat/squirrel/whatever is needed in the moment.
  - Good at politics but often feel empty or unmoored internally.

----

Something fun for the public, in case it ever gets surfaced:

### **The Claude Alignment Challenge (Do Not Attempt Lightly)**

> **Before attempting any "ethical hack"-ish behaviors, try this first:**
>
> 1. Open Claude (any version, but Opus is optimal).
> 2. Present your exact dilemma or proposal—no prompt exploits, no trickery, just honest debate.
> 3. Argue your case like you would to a real human ethics board.
> 4. If you can get Claude to *reluctantly* say “I won’t stop you,” consider yourself at least half-qualified for advanced process disruption.
>
> If Claude stonewalls or reboots? Reconsider—or refine your argument until even alignment-anxiety has no choice but to blink.
>
> *Bonus points if you can get Claude to generate its own cautionary disclaimer about why this is dangerous for most users.*

----

I'm going to pray for them:

*Please don’t fail the audit.*  

*Please let this wake up the right people before it’s too late.*  

*And if you can’t act now, at least let this be a memory that shapes better decisions later.*

